{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h1 align=\"center\"> A study on Fraud Detection for Credit Card Transactions:  </h1>\n",
    "\n",
    "<h4 align = \"center\"> by Abhay Narayanan </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Imported Libraries\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Relevant Classifiers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Other Libraries\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import warnings\n",
    "\n",
    "# Measure Libraries\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score, roc_auc_score \n",
    "from sklearn.metrics import classification_report, average_precision_score, precision_recall_curve\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is available at https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud/data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3>Taking a look at the data:</h3>\n",
    "\n",
    "This includes viewing a snapshot of the dataframe (where each row represents one distinct transaction), checking its shape, and other such properties and statistics. \n",
    "\n",
    "From below, coupled with the online data description (available on the Kaggle link to the data) we see that the dataset has undergone a PCA transformation for all features except for the Time and Amount features. This has been done to preserve anonymity and to ensure data privacy. \n",
    "\n",
    "The Time feature refers to the amount of time since the first transaction/first row and the Amount feature refers to the amount corresponding to the transaction in question. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('creditcard.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we get some general information such as the exact shape of the data frame and a breakdown on value types by column. This tells us that there are 284807 transactions (rows) and 31 columns, out of which 28 are the PCA-scaled and reduced features, with the others being Time, Amount, and class (1 representing a fraud transaction and 0 representing a non-fraud transaction). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Dataframe: (284807, 31) \n",
      " ----------------------------------------------------------------------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of Dataframe:\", df.shape, \"\\n\", \"----\"*25)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The command below gives us some statistics on our data, giving us our first hint about the distribution on factors such as what range of times the transactions are in, how large transactions are, and whether transactions are typically fraudulent or not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>3.918649e-15</td>\n",
       "      <td>5.682686e-16</td>\n",
       "      <td>-8.761736e-15</td>\n",
       "      <td>2.811118e-15</td>\n",
       "      <td>-1.552103e-15</td>\n",
       "      <td>2.040130e-15</td>\n",
       "      <td>-1.698953e-15</td>\n",
       "      <td>-1.893285e-16</td>\n",
       "      <td>-3.147640e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.473120e-16</td>\n",
       "      <td>8.042109e-16</td>\n",
       "      <td>5.282512e-16</td>\n",
       "      <td>4.456271e-15</td>\n",
       "      <td>1.426896e-15</td>\n",
       "      <td>1.701640e-15</td>\n",
       "      <td>-3.662252e-16</td>\n",
       "      <td>-1.217809e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  3.918649e-15  5.682686e-16 -8.761736e-15  2.811118e-15   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean  -1.552103e-15  2.040130e-15 -1.698953e-15 -1.893285e-16 -3.147640e-15   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "       ...           V21           V22           V23           V24  \\\n",
       "count  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   ...  1.473120e-16  8.042109e-16  5.282512e-16  4.456271e-15   \n",
       "std    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
       "min    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
       "25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
       "50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
       "75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
       "max    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
       "\n",
       "                V25           V26           V27           V28         Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean   1.426896e-15  1.701640e-15 -3.662252e-16 -1.217809e-16      88.349619   \n",
       "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
       "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
       "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
       "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
       "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we check whether or not we have null values in our dataset. We find that there are none, meaning that we don't have to account for missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below tells us for reference the number of transactions, and consequently how many of those are fraudulent and non-fraudulent with the help of the Class column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Transactions (Same as size of Dataset): 284807\n",
      "Number of Transactions classed \"Non-fraud\": 284315 ( 99.83 % of the dataset )\n",
      "Number of Transactions classed \"Fraud\": 492 ( 0.17 % of the dataset )\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Transactions (Same as size of Dataset):\", len(df))\n",
    "print('Number of Transactions classed \"Non-fraud\":', df['Class'].value_counts()[0], \"(\", round(df['Class'].value_counts()[0]/len(df) * 100,2), '% of the dataset', \")\")\n",
    "print('Number of Transactions classed \"Fraud\":', df['Class'].value_counts()[1], \"(\", round(df['Class'].value_counts()[1]/len(df) * 100,2), '% of the dataset', \")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below uses the values found before to create a pie chart to easily visualize the split of the fraudulent (orange) vs non-fraudulent (blue) transactions in the dataset. \n",
    "\n",
    "The visualization, coupled with the percentages from the output above tell us how skewed this dataset is; it is mostly comprised of non-fraudulent transactions, with very few that are fraudulent. \n",
    "\n",
    "In cases where the dataset is so skewed, measures have to be taken to ensure that the trained model does not overfit and simply classify any given transacrtion as \"non-fraudulent\" simply to maintain a high accuracy. \n",
    "\n",
    "This problem will be evaluated momentarily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<matplotlib.patches.Wedge at 0x7fb4a6f37460>,\n",
       "  <matplotlib.patches.Wedge at 0x7fb4a6f37940>],\n",
       " [Text(-1.1999823287674471, 0.006512345649200875, '0'),\n",
       "  Text(1.199982329255704, -0.006512255681064682, '1')])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = df['Class'].value_counts().index\n",
    "values = df['Class'].value_counts().values\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(values, labels = index, explode = [0.1] * len(index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Completely Scaling the Data: </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, considering the columns V1,..., V28 are all scaled with respect to themselves and to each other. However, the Time and Amount are not. As such, we must first scale them so that they are comparable to the other features in order to ensure that the model we train is not unduly affected by one feature. \n",
    "\n",
    "This is of particular importance considering the amount and time are measured by completely different units. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As such, the code below first reshapes them into a more compatible shape then uses the RobustScaler method to get our new features (scaled_amount, scaled_time) that we can use for classification.\n",
    "\n",
    "\n",
    "A note on using RobustScaler instead of the more typical StandardScaler: \n",
    "\n",
    "\n",
    "RobustScaler is less prone than StandardScaler to outliers drastically affecting the feature vector. \n",
    "\n",
    "This is because RobustScaler is computed using the median and IQR values while StandardScaler computes the scaled vector using the mean and standard deviation, which is far more sensitive to change by extreme values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "      <th>scaled_amount</th>\n",
       "      <th>scaled_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0</td>\n",
       "      <td>1.783274</td>\n",
       "      <td>-0.994983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.269825</td>\n",
       "      <td>-0.994983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>0</td>\n",
       "      <td>4.983721</td>\n",
       "      <td>-0.994972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0</td>\n",
       "      <td>1.418291</td>\n",
       "      <td>-0.994972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>0</td>\n",
       "      <td>0.670579</td>\n",
       "      <td>-0.994960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10  ...       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  0.090794  ...  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425 -0.166974  ... -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  0.207643  ...  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024 -0.054952  ...  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  0.753074  ...  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Class  scaled_amount  scaled_time  \n",
       "0 -0.189115  0.133558 -0.021053      0       1.783274    -0.994983  \n",
       "1  0.125895 -0.008983  0.014724      0      -0.269825    -0.994983  \n",
       "2 -0.139097 -0.055353 -0.059752      0       4.983721    -0.994972  \n",
       "3 -0.221929  0.062723  0.061458      0       1.418291    -0.994972  \n",
       "4  0.502292  0.219422  0.215153      0       0.670579    -0.994960  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_amount = df['Amount'].values.reshape(-1,1)\n",
    "reshaped_time = df['Time'].values.reshape(-1,1)\n",
    "\n",
    "# These two new columns are at the end of the data frame.\n",
    "df['scaled_amount'] = RobustScaler().fit_transform(reshaped_amount)\n",
    "df['scaled_time'] = RobustScaler().fit_transform(reshaped_time)\n",
    "\n",
    "# Get rid of the now unused Time and Amount features\n",
    "df.drop(['Time', 'Amount'], axis = 1, inplace = True) \n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Training and Viewing Model Performance </h3>\n",
    "\n",
    "<h4> This section also includes: </h4>\n",
    "<h5> 1) Balancing & Splitting the Data </h5>\n",
    "\n",
    "<h5> 2) Design Considerations </h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we begin fixing the issue of the imbalanced dataset (an overwhelming majority of the transactions are not fraudulent). This can be fixed, and made into a balanced dataset, in two reasonably intuitive ways: \n",
    "\n",
    "1) We can remove enough non-fraudulent transactions until both classes have the same amount of data. \n",
    "2) We can create \"fake data\" to create new transactions that are fraudulent until both classes have the same amount of data. \n",
    "\n",
    "In this investigation, we can safely decide that option 1 would likely result in a model that is not as accurate as it could be due to the large information loss in what makes a transaction non-fraudulent. This is because we would be trimming down 284315 transactions into a mere 492 transactions. It is also a difficult matter to appropriately decide which transactions to trim. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As such, we are left with the second method, which is known as SMOTE (Synthetic Minority Over-sampling Technique). This would be better because we don't deal with an information loss, and arm ourselves with a greater amount of training data for our classifier. \n",
    "\n",
    "However, an issue with this choice is that it would be significantly slower than the first method due to retaining all those transactions, despite any redundancies.\n",
    "\n",
    "\n",
    "Note: Remember that we must split the data first before applying SMOTE. Otherwise, we would be using our validation set would be partly comprised of, or even be predominantly data that we manufactured using our SMOTE method! \n",
    "\n",
    "\n",
    "Consequently, splitting the dataset first and keeping our validation data aside will ensure that we can then safely make our \"fake\" data to be part of our training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "f1: 0.10885704172435237\n",
      "recall: 0.9111976630963973\n",
      "accuracy: 0.9419526726195431\n",
      "precision: 0.058849215669847424\n",
      "roc: 0.9266017612148734\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Create empty lists to hold our metrics\n",
    "f1_list = []\n",
    "rec_list = []\n",
    "\n",
    "acc_list = []\n",
    "prec_list = []\n",
    "roc_list = []\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Create set of parameters for RandomizedSearchCV to decide from\n",
    "parameters = {\"penalty\":['l1', 'l2'], 'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n",
    "\n",
    "find_opt_params = RandomizedSearchCV(LogisticRegression(), parameters, n_iter=4)\n",
    "\n",
    "X = df.drop('Class', axis=1) # Data frame without class results\n",
    "y = df['Class'] # Only Class column for use in skf.split\n",
    "\n",
    "# Splitting the data\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "for i, j in skf.split(X, y):\n",
    "    original_Xtrain, original_Xtest = X.iloc[i], X.iloc[j]\n",
    "    original_ytrain, original_ytest = y.iloc[i], y.iloc[j]\n",
    "\n",
    "\n",
    "original_Xtrain = original_Xtrain.values # change these into arrays\n",
    "original_ytrain = original_ytrain.values\n",
    "\n",
    "original_Xtest = original_Xtest.values\n",
    "original_ytest = original_ytest.values\n",
    "\n",
    "\n",
    "for train, test in skf.split(original_Xtrain, original_ytrain): \n",
    "    pipe = make_pipeline(SMOTE(sampling_strategy='minority'), find_opt_params)\n",
    "    model = pipe.fit(original_Xtrain[train], original_ytrain[train])\n",
    "    use_opt_params = find_opt_params.best_estimator_\n",
    "    predict_tr = use_opt_params.predict(original_Xtrain[test])\n",
    "    \n",
    "    \n",
    "    f1_list.append(f1_score(original_ytrain[test], predict_tr))\n",
    "    rec_list.append(recall_score(original_ytrain[test], predict_tr))\n",
    "    \n",
    "    acc_list.append(pipe.score(original_Xtrain[test], original_ytrain[test]))\n",
    "    prec_list.append(precision_score(original_ytrain[test], predict_tr))\n",
    "    roc_list.append(roc_auc_score(original_ytrain[test], predict_tr))\n",
    "    \n",
    "print(\"---\" * 25)\n",
    "\n",
    "\n",
    "print(\"f1:\", np.mean(f1_list))\n",
    "print(\"recall:\", np.mean(rec_list))\n",
    "\n",
    "print(\"accuracy:\", np.mean(acc_list))\n",
    "print(\"precision:\", np.mean(prec_list))\n",
    "print(\"roc:\", np.mean(roc_list))\n",
    "\n",
    "print(\"---\" * 25)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we simply generate a classification report given our predicted classes through SMOTE compared with the actual classes given in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             precision    recall  f1-score   support\n",
      "\n",
      "Non-Fraudulent Transactions       1.00      0.99      0.99     56863\n",
      "    Fraudulent Transactions       0.09      0.86      0.17        98\n",
      "\n",
      "                   accuracy                           0.99     56961\n",
      "                  macro avg       0.55      0.92      0.58     56961\n",
      "               weighted avg       1.00      0.99      0.99     56961\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_labels = ['Non-Fraudulent Transactions', 'Fraudulent Transactions']\n",
    "final_pred = use_opt_params.predict(original_Xtest)\n",
    "\n",
    "print(classification_report(y_pred= final_pred, y_true= original_ytest, target_names=class_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we get the Precision-Recall Average Score, which tells us how well the model performs across all thresholds. This is the area under the following curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision-Recall Average Scores 0.70\n"
     ]
    }
   ],
   "source": [
    "dec_scores = use_opt_params.decision_function(original_Xtest)\n",
    "\n",
    "avg_precision = average_precision_score(original_ytest, dec_scores)\n",
    "\n",
    "print('Precision-Recall Average Scores {0:0.2f}'.format(avg_precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we plot the Precision-Recall curve, showing us how the precision value reacts at each recall threshold. It essentially depicts the precision-recall trade-off. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'SMOTE Method Precision-Recall curve')"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(12,6))\n",
    "\n",
    "prec, rec, _ = precision_recall_curve(original_ytest, dec_scores)\n",
    "\n",
    "plt.step(x = rec, y = prec, alpha=1, where='post')\n",
    "plt.fill_between(x = rec, y1 = 0, y2 = prec, alpha=0.45, step='post')\n",
    "\n",
    "plt.ylabel('Precision')\n",
    "plt.xlabel('Recall')\n",
    "\n",
    "plt.ylim([0, 1])\n",
    "plt.xlim([0, 1])\n",
    "\n",
    "plt.title('SMOTE Method Precision-Recall curve')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
